{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn6YRzBImPvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import codecs\n",
        "import sys\n",
        "import pickle\n",
        "\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import callbacks\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, LSTM, Embedding, Dropout, BatchNormalization, Activation, Bidirectional\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.utils import plot_model \n",
        "from IPython.display import Image\n",
        "import pydot\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "from string import punctuation\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "#from keras import initializations\n",
        "from keras import initializers, regularizers, constraints"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkqWo9g4Fny0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d192f1ec-a6d1-4978-c276-e7210a94b3cc"
      },
      "source": [
        "!git clone https://github.com/Jayagn/Fake-news-challenge.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Fake-news-challenge'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 11 (delta 0), reused 11 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (11/11), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eypn7Gu-GCah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b8e85d7-69a2-4ac2-892a-dc760bcebb1a"
      },
      "source": [
        "cd Fake-news-challenge/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Fake-news-challenge\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1qUfrGSyUa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = './data'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXjcIhaeyW1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the text files of fnc data\n",
        "bodies = pd.read_csv(DATA_DIR + '/body_id.csv')\n",
        "\n",
        "test_df = pd.read_csv(DATA_DIR + '/test.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idPft-OjyZ9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.replace('unrelated',1,True)\n",
        "test_df.replace('agree',2,True)\n",
        "test_df.replace('disagree',3,True)\n",
        "test_df.replace('discuss',4,True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGSuPf_e5p4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combine_df_train = train_df.join(bodies.set_index('Body ID'), on='Body ID')\n",
        "combine_df_test = test_df.join(bodies.set_index('Body ID'), on='Body ID')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WuOVSrB5sJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-processing involves removal of puctuations and converting text to lower case\n",
        "word_seq_head_test = [text_to_word_sequence(head) for head in combine_df_test['Headline']]\n",
        "word_seq_bodies_test = [text_to_word_sequence(body) for body in combine_df_test['articleBody']]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09GqMlgk5uqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_seq = []\n",
        "\n",
        "for i in range(len(word_seq_head_test)):\n",
        "    word_seq.append(word_seq_head_test[i])\n",
        "for i in range(len(word_seq_bodies_test)):\n",
        "    word_seq.append(word_seq_bodies_test[i])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlUXulwf5yoq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d5a0890-01bb-40e3-ea4a-93920e803386"
      },
      "source": [
        "\n",
        "filter_list = '!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "MAX_VOCAB_SIZE = 5000\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters=filter_list)\n",
        "tokenizer.fit_on_texts([seq for seq in word_seq])\n",
        "#because it only includes unique words(tokens)\n",
        "\n",
        "print(\"Number of words in vocabulary:\", len(tokenizer.word_index))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocabulary: 20238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNC-2Tbv94vG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "   \n",
        "word_seq_test = [list(i) for i in word_seq_head_test]\n",
        "for i in range(len(word_seq_head_test)):\n",
        "    word_seq_test[i].extend(word_seq_bodies_test[i])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaIi66bd9-UJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the sequence of words to sequnce of indices\n",
        "X_test = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_test])\n",
        "X_test = pad_sequences(X_test, maxlen=MAX_SENT_LEN, padding='post', truncating='post')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx3nvNOEOdnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "model = models.load_model('bidirectional_lstm_700.h5')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQJlN1gbOvJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model.predict([X_test])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srqPC3hROyL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = [np.argmax(p, axis = -1) for p in preds]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nafcgZjSO0ce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for i in range(len(outputs)):\n",
        "    if outputs[i] == 0: outputs[i] = \"unrelated\"\n",
        "    if outputs[i] == 1: outputs[i] = \"disagree\"\n",
        "    if outputs[i] == 2: outputs[i] = \"agree\"\n",
        "    if outputs[i] == 3: outputs[i] = \"discuss\"\n",
        "        \n",
        "df_predicted = pd.DataFrame({'Stance': outputs})\n",
        "result = pd.concat([test_df, df_predicted], axis=1, sort=False)\n",
        "result.to_csv('./bidirectional_lstm_700_answer.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFK9O7Z5Qmco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}